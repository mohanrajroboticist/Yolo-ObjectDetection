{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b0b65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06948b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo2bbox(box):\n",
    "    x_min, y_min = box[0] - box[2]/2, box[1] - box[3]/2\n",
    "    x_max, y_max = box[0] + box[2]/2, box[1] + box[3]/2\n",
    "    return x_min, y_min, x_max, y_max\n",
    "\n",
    "\n",
    "def plot_box(image, boxes, labels):\n",
    "    img_h, img_w, _ = image.shape\n",
    "    for i, box in enumerate(boxes):\n",
    "        x_min, y_min, x_max, y_max = yolo2bbox(box)\n",
    "        x_1 = int(x_min * img_w)\n",
    "        y_1 = int(y_min * img_h)\n",
    "        x_2 = int(x_max * img_w)\n",
    "        y_2 = int(y_max * img_h)\n",
    "        width = x_2 - x_1\n",
    "        height = y_2 - y_1\n",
    "        class_name = class_names[int(labels[i])]\n",
    "        color = colors[class_names.index(class_name)]\n",
    "        cv2.rectangle(image, (x_1, y_1), (x_2, y_2), color=color, thickness=2)\n",
    "        \n",
    "        font_scale = min(1, max(3, int(img_w/500)))\n",
    "        font_thickness = min(2, max(10, int(img_w/50)))\n",
    "        tw, th = cv2.getTextSize(class_name, 0, fontScale=font_scale, thickness=font_thickness)[0]\n",
    "        p1, p2 = (int(x_1), int(y_1)), (int(x_2), int(y_2))\n",
    "        p2 = p1[0] + tw, p1[1] + -th - 10\n",
    "        cv2.rectangle(image, p1, p2, color=color, thickness=-1,)\n",
    "        cv2.putText(image, class_name, (x_1+1, y_1-10), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255, 255, 255),\n",
    "        font_thickness)\n",
    "    return image\n",
    "\n",
    "\n",
    "\n",
    "def plot(images_path, labels_path, display_qty):\n",
    "    training_images = glob.glob(images_path)\n",
    "    training_labels = glob.glob(labels_path)\n",
    "    training_images.sort()\n",
    "    training_labels.sort()\n",
    "    \n",
    "    images_qty = len(training_images)\n",
    "    \n",
    "    plt.figure(figsize=(15,12))\n",
    "    for i in range(display_qty):\n",
    "        j = random.randint(0, images_qty-1)\n",
    "        image = cv2.imread(training_images[j])\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        with open(training_labels[j], 'r') as f:\n",
    "            textfile_lines = f.readlines()\n",
    "            for textfile_line in textfile_lines:\n",
    "                label = textfile_line.split(' ')[0]\n",
    "                x_c, y_c, w, h = textfile_line.split(' ')[1:]\n",
    "                x_c = float(x_c)\n",
    "                y_c = float(y_c)\n",
    "                w   = float(w)\n",
    "                h   = float(h.split('\\n')[0])\n",
    "                boxes.append([x_c, y_c, w, h])\n",
    "                labels.append(label)\n",
    "        plot_box(image, boxes, labels)\n",
    "        plt.subplot(3,3, i+1)\n",
    "        im_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        plt.imshow(im_rgb)\n",
    "        plt.axis('off')\n",
    "    \n",
    "\n",
    "# class_names = ['F20_20_B', 'R20', 'S40_40_B', 'S40_40_G', 'axis', 'bearing_box', 'bracket', 'brown_box', 'cup', \n",
    "#                'dishwasher_soap', 'eye_glasses', 'insulation_tape', 'motor', 'pringles', 'screw_driver', 'sponge', \n",
    "#                'spoon', 'tennis_ball', 'toothbrush', 'towel']\n",
    "\n",
    "# image_paths = 'dataset/train1/images/*'\n",
    "# label_paths = 'dataset/train1/labels/*'\n",
    "\n",
    "\n",
    "\n",
    "class_names = ['F20_20_B', 'R20', 'S40_40_B', 'S40_40_G', 'axis', 'bearing_box', 'bracket', 'brown_box', 'cup', \n",
    "               'dishwasher_soap', 'eye_glasses', 'insulation_tape', 'motor', 'pringles', 'screw_driver', 'sponge', \n",
    "               'spoon', 'tennis_ball', 'toothbrush', 'towel', \"cereal\",\"chocolate_milk\", \"heineken\",\"iron_man\" ,\"medicine\"\n",
    "               ,\"milk_bottle\",\"milk_box\",\"monster\" ,\"purple_juice\" ,\"red_juice\" ,\"shampoo\" ,\"tea_box\", \"yellow_juice\", \"paprika\"]\n",
    "\n",
    "image_paths = 'dataset/test300/images/*'\n",
    "label_paths = 'dataset/test300/labels/*'\n",
    "\n",
    "\n",
    "colors = np.random.uniform(0, 255, size=(len(class_names), 3))\n",
    "plot(image_paths, label_paths,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22694bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('yolov5'):\n",
    "    !git clone https://github.com/ultralytics/yolov5.git\n",
    "\n",
    "def SetResultDirectory():\n",
    "    global Folder_count\n",
    "    Folder_count = len(glob.glob(\"runs/train/*\"))\n",
    "    if Train:\n",
    "        DirectoryName = \"./results_\" + str(Folder_count+1)\n",
    "    else:\n",
    "        DirectoryName = \"./results_\" + str(Folder_count)\n",
    "    return DirectoryName\n",
    "\n",
    "\n",
    "Train  = True\n",
    "Freeze = True\n",
    "Epochs = 100\n",
    "Folder_count = 0\n",
    "%cd yolov5\n",
    "Result_Directory = SetResultDirectory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab3277c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Train:\n",
    "    if Freeze:\n",
    "        !python -m torch.distributed.run --nproc_per_node 1 train.py \\\n",
    "        --batch  4\\\n",
    "        --data ../dataset/MergedDataset200.yaml \\\n",
    "        --weights yolov5m.pt \\\n",
    "        --img 640 \\\n",
    "        --epochs {Epochs} \\\n",
    "        --name {Result_Directory} \\\n",
    "        --device 1 \\\n",
    "        --freeze 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 \\\n",
    "#         --hyp data/hyps/hyp.no-augmentation.yaml \n",
    "    else:\n",
    "        !python -m torch.distributed.run --nproc_per_node 2 train.py \\\n",
    "        --batch  4\\\n",
    "        --data ../dataset/MergedDataset200.yaml \\\n",
    "        --weights yolov5m.pt \\\n",
    "        --img 640 \\\n",
    "        --epochs {Epochs} \\\n",
    "        --name {Result_Directory} \\\n",
    "        --device 0,1 \\\n",
    "        \n",
    "    Result_Directory = \"runs/train/results_\" + str(Folder_count + 1)\n",
    "    \n",
    "else:\n",
    "    Result_Directory = \"runs/train/results_\" + str(Folder_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a481674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_valid_results(Result_Directory):\n",
    "    validation_pred_images = glob.glob(Result_Directory + \"/*_pred.jpg\")\n",
    "    for pred_image in validation_pred_images:\n",
    "        image = cv2.imread(pred_image)\n",
    "        plt.figure(figsize=(19, 16))\n",
    "        plt.imshow(image[:, :, ::-1])\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "show_valid_results(Result_Directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6842f318",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(Result_Directory, data_path):\n",
    "    infer_folder_count = len(glob.glob('runs/detect/*'))\n",
    "    Detect_store = f\"./inference_{infer_folder_count+1}\"\n",
    "    Best_weights = f\"{Result_Directory}/weights/best.pt\"\n",
    "    \n",
    "    !python -m torch.distributed.run --nproc_per_node 1 detect.py --weights {Best_weights} \\\n",
    "    --source {data_path} \\\n",
    "    --name {Detect_store}\\\n",
    "    --device 1\n",
    "    \n",
    "    return Detect_store\n",
    "\n",
    "\n",
    "on_single_image = False\n",
    "if on_single_image:\n",
    "    IMAGE_INFER_DIR = inference(Result_Directory, '../dataset/test200/Test_Image.jpg')\n",
    "else:\n",
    "    IMAGE_INFER_DIR = inference(Result_Directory, '../dataset/test200/Multiple_images')\n",
    "\n",
    "# if on_single_image:\n",
    "#     IMAGE_INFER_DIR = inference(Result_Directory, '../dataset/test1/Test_Image.jpg')\n",
    "# else:\n",
    "#     IMAGE_INFER_DIR = inference(Result_Directory, '../dataset/test1/Multiple_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf446b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(INFER_DIR):\n",
    "    INFER_PATH = f\"{INFER_DIR}\"\n",
    "    infer_images = glob.glob(f\"{INFER_PATH}/*\")\n",
    "    for pred_image in infer_images:\n",
    "        image = cv2.imread(pred_image)\n",
    "        plt.figure(figsize=(19, 16))\n",
    "        plt.imshow(image[:, :, ::-1])\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "visualize('runs/detect/' + IMAGE_INFER_DIR[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b964c577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# infer_folder_count = len(glob.glob('runs/detect/*'))\n",
    "# Detect_store = f\"./inference_{infer_folder_count+1}\"\n",
    "# Best_weights = f\"{Result_Directory}/weights/best.pt\"\n",
    "\n",
    "# !python val.py --weights runs/train/results_merged3/weights/best.pt \\\n",
    "# --data ../dataset/TestMergeDataset100.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ac2fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd yolov5\n",
    "#!python export.py --weights /home/jovyan/public/mnadar/result/results_0/weights/best.pt --include onnx\n",
    "# !python export.py --weights /home/jovyan/public/mnadar/result/results_0/weights/best.pt --include edgetpu\n",
    "#!python export.py --weights /home/jovyan/public/mnadar/result/results_0/weights/best.pt --include tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4307f106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference():\n",
    "    infer_folder_count = len(glob.glob('runs/detect/*'))\n",
    "    Detect_store = f\"./inference_{infer_folder_count+1}\"\n",
    "    \n",
    "    Result_Directory = \"runs/train/results_merged\" + str(1)\n",
    "    Best_weights = f\"{Result_Directory}/weights/best.pt\"\n",
    "    \n",
    "    !python -m torch.distributed.run --nproc_per_node 1 detect.py --weights {Best_weights} \\\n",
    "    --source ../dataset/final_test \\\n",
    "    --name {Detect_store}\\\n",
    "    --device 1\n",
    "\n",
    "inference()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
